{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780d82fc",
   "metadata": {},
   "source": [
    "TMDB Movie Data Analysis Project - Phase 2: Data Cleaning \\\n",
    "Step 3: Complete Data Cleaning & Transformation\n",
    "\n",
    "This script performs all required cleaning operations on the raw movie data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c3b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c02d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loaded raw data: 18 rows × 28 columns\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD RAW DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Load raw data\n",
    "df = pd.read_csv('movies_raw_data.csv')\n",
    "print(f\"\\n Loaded raw data: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "\n",
    "# Create a copy to preserve original\n",
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d3003cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS FOR JSON EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "def safe_eval(value):\n",
    "    \"\"\"\n",
    "    Safely convert string representation of list/dict to actual Python object.\n",
    "    Returns None if conversion fails.\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or value == '' or value == '[]':\n",
    "        return None\n",
    "    try:\n",
    "        # Try to evaluate as Python literal\n",
    "        return literal_eval(value) if isinstance(value, str) else value\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_names_from_list(data, key='name'):\n",
    "    \"\"\"\n",
    "    Extract names from a list of dictionaries.\n",
    "    \n",
    "    Example input: [{'id': 28, 'name': 'Action'}, {'id': 12, 'name': 'Adventure'}]\n",
    "    Example output: 'Action|Adventure'\n",
    "    \"\"\"\n",
    "    if not data or pd.isna(data):\n",
    "        return None\n",
    "    \n",
    "    # If it's a string, convert to list\n",
    "    if isinstance(data, str):\n",
    "        data = safe_eval(data)\n",
    "    \n",
    "    # If still not a list, return None\n",
    "    if not isinstance(data, list) or len(data) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Extract names and join with |\n",
    "    try:\n",
    "        names = [item[key] for item in data if isinstance(item, dict) and key in item]\n",
    "        return '|'.join(names) if names else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_collection_name(data):\n",
    "    \"\"\"\n",
    "    Extract collection name from belongs_to_collection field.\n",
    "    \n",
    "    Example input: {'id': 86311, 'name': 'The Avengers Collection', ...}\n",
    "    Example output: 'The Avengers Collection'\n",
    "    \"\"\"\n",
    "    if pd.isna(data) or data == '' or data == '{}':\n",
    "        return None\n",
    "    \n",
    "    # If it's a string, convert to dict\n",
    "    if isinstance(data, str):\n",
    "        data = safe_eval(data)\n",
    "    \n",
    "    # Extract name\n",
    "    if isinstance(data, dict) and 'name' in data:\n",
    "        return data['name']\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def find_director(crew_data):\n",
    "    \"\"\"\n",
    "    Find the director from crew list.\n",
    "    \n",
    "    Example input: [{'name': 'John Doe', 'job': 'Director'}, ...]\n",
    "    Example output: 'John Doe'\n",
    "    \"\"\"\n",
    "    if not crew_data or pd.isna(crew_data):\n",
    "        return None\n",
    "    \n",
    "    # If it's a string, convert to list\n",
    "    if isinstance(crew_data, str):\n",
    "        crew_data = safe_eval(crew_data)\n",
    "    \n",
    "    if not isinstance(crew_data, list):\n",
    "        return None\n",
    "    \n",
    "    # Find first person with job='Director'\n",
    "    try:\n",
    "        for person in crew_data:\n",
    "            if isinstance(person, dict) and person.get('job') == 'Director':\n",
    "                return person.get('name')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_cast_names(cast_data, max_names=5):\n",
    "    \"\"\"\n",
    "    Extract top cast member names.\n",
    "    \n",
    "    Example input: [{'name': 'Robert Downey Jr.', 'order': 0}, ...]\n",
    "    Example output: 'Robert Downey Jr.|Chris Evans|Mark Ruffalo|...'\n",
    "    \"\"\"\n",
    "    if not cast_data or pd.isna(cast_data):\n",
    "        return None\n",
    "    \n",
    "    # If it's a string, convert to list\n",
    "    if isinstance(cast_data, str):\n",
    "        cast_data = safe_eval(cast_data)\n",
    "    \n",
    "    if not isinstance(cast_data, list) or len(cast_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Extract names (top 5 by default)\n",
    "    try:\n",
    "        names = [person['name'] for person in cast_data[:max_names] \n",
    "                 if isinstance(person, dict) and 'name' in person]\n",
    "        return '|'.join(names) if names else None\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "469cf5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dropped 5 columns: adult, imdb_id, original_title, video, homepage\n",
      " New shape: 18 rows × 23 columns\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 1: Drop Unwanted Columns\n",
    "# ============================================================================\n",
    "\n",
    "columns_to_drop = ['adult', 'imdb_id', 'original_title', 'video', 'homepage']\n",
    "\n",
    "# Only drop columns that exist\n",
    "existing_to_drop = [col for col in columns_to_drop if col in df_clean.columns]\n",
    "\n",
    "if existing_to_drop:\n",
    "    df_clean = df_clean.drop(columns=existing_to_drop)\n",
    "    print(f\" Dropped {len(existing_to_drop)} columns: {', '.join(existing_to_drop)}\")\n",
    "else:\n",
    "    print(\" No columns to drop (already removed or never existed)\")\n",
    "\n",
    "print(f\" New shape: {df_clean.shape[0]} rows × {df_clean.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c1a5186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "2. EXTRACTING DATA FROM JSON COLUMNS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  2.1 Extracting collection names...\n",
      "       Extracted collection names: 16 movies belong to a collection\n",
      "\n",
      "  2.2 Extracting genres...\n",
      "       Genres extracted and formatted with '|' separator\n",
      "      Example: Adventure|Science Fiction|Action...\n",
      "\n",
      "  2.3 Extracting spoken languages...\n",
      "       Languages extracted\n",
      "\n",
      "  2.4 Extracting production countries...\n",
      "       Countries extracted\n",
      "\n",
      "  2.5 Extracting production companies...\n",
      "       Companies extracted\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 2: Extract Data from JSON Columns\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"2. EXTRACTING DATA FROM JSON COLUMNS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 2.1 Extract Collection Name\n",
    "if 'belongs_to_collection' in df_clean.columns:\n",
    "    print(\"\\n  2.1 Extracting collection names...\")\n",
    "    df_clean['belongs_to_collection'] = df_clean['belongs_to_collection'].apply(extract_collection_name)\n",
    "    non_null = df_clean['belongs_to_collection'].notna().sum()\n",
    "    print(f\"       Extracted collection names: {non_null} movies belong to a collection\")\n",
    "\n",
    "# 2.2 Extract Genres\n",
    "if 'genres' in df_clean.columns:\n",
    "    print(\"\\n  2.2 Extracting genres...\")\n",
    "    df_clean['genres'] = df_clean['genres'].apply(extract_names_from_list)\n",
    "    print(f\"       Genres extracted and formatted with '|' separator\")\n",
    "\n",
    "    # Safe example printing\n",
    "    genres_non_null = df_clean['genres'].dropna()\n",
    "    if len(genres_non_null) > 0:\n",
    "        print(f\"      Example: {genres_non_null.iloc[0][:50]}...\")\n",
    "    else:\n",
    "        print(\"      Example: No non-null genre entries available.\")\n",
    "\n",
    "# 2.3 Extract Spoken Languages\n",
    "if 'spoken_languages' in df_clean.columns:\n",
    "    print(\"\\n  2.3 Extracting spoken languages...\")\n",
    "    df_clean['spoken_languages'] = df_clean['spoken_languages'].apply(\n",
    "        lambda x: extract_names_from_list(x, key='english_name')\n",
    "    )\n",
    "    print(f\"       Languages extracted\")\n",
    "\n",
    "# 2.4 Extract Production Countries\n",
    "if 'production_countries' in df_clean.columns:\n",
    "    print(\"\\n  2.4 Extracting production countries...\")\n",
    "    df_clean['production_countries'] = df_clean['production_countries'].apply(extract_names_from_list)\n",
    "    print(f\"       Countries extracted\")\n",
    "\n",
    "# 2.5 Extract Production Companies\n",
    "if 'production_companies' in df_clean.columns:\n",
    "    print(\"\\n  2.5 Extracting production companies...\")\n",
    "    df_clean['production_companies'] = df_clean['production_companies'].apply(extract_names_from_list)\n",
    "    print(f\"       Companies extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4f34c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "3. PROCESSING CAST & CREW DATA\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  3.1 Finding directors...\n",
      "       Directors found for 18 movies\n",
      "\n",
      "  3.2 Calculating crew size...\n",
      "       Crew size calculated\n",
      "\n",
      "  3.3 Extracting cast names...\n",
      "       Top 5 cast members extracted per movie\n",
      "\n",
      "  3.4 Calculating cast size...\n",
      "       Cast size calculated\n",
      "\n",
      "   Dropped 'crew' column (no longer needed)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 3: Process Cast & Crew\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"3. PROCESSING CAST & CREW DATA\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 3.1 Extract Director\n",
    "if 'crew' in df_clean.columns:\n",
    "    print(\"\\n  3.1 Finding directors...\")\n",
    "    df_clean['director'] = df_clean['crew'].apply(find_director)\n",
    "    directors_found = df_clean['director'].notna().sum()\n",
    "    print(f\"       Directors found for {directors_found} movies\")\n",
    "\n",
    "# 3.2 Calculate Crew Size\n",
    "if 'crew' in df_clean.columns:\n",
    "    print(\"\\n  3.2 Calculating crew size...\")\n",
    "    df_clean['crew_size'] = df_clean['crew'].apply(\n",
    "        lambda x: len(safe_eval(x)) if safe_eval(x) else 0\n",
    "    )\n",
    "    print(f\"       Crew size calculated\")\n",
    "\n",
    "# 3.3 Extract Cast Names\n",
    "if 'cast' in df_clean.columns:\n",
    "    print(\"\\n  3.3 Extracting cast names...\")\n",
    "    df_clean['cast'] = df_clean['cast'].apply(lambda x: extract_cast_names(x, max_names=5))\n",
    "    print(f\"       Top 5 cast members extracted per movie\")\n",
    "\n",
    "# 3.4 Calculate Cast Size (before extraction)\n",
    "# We need to recalculate from raw data since we already modified cast\n",
    "if 'cast' in df.columns:\n",
    "    print(\"\\n  3.4 Calculating cast size...\")\n",
    "    df_clean['cast_size'] = df['cast'].apply(\n",
    "        lambda x: len(safe_eval(x)) if safe_eval(x) else 0\n",
    "    )\n",
    "    print(f\"       Cast size calculated\")\n",
    "\n",
    "# Drop the crew column (we don't need it anymore)\n",
    "if 'crew' in df_clean.columns:\n",
    "    df_clean = df_clean.drop(columns=['crew'])\n",
    "    print(\"\\n   Dropped 'crew' column (no longer needed)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e1ae311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "4. CONVERTING DATA TYPES\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  4.1 Converting budget and revenue to millions USD...\n",
      "       Budget and revenue converted to millions USD\n",
      "       Zeros replaced with NaN\n",
      "\n",
      "  4.2 Converting release_date to datetime...\n",
      "       Release date converted to datetime format\n",
      "\n",
      "  4.3 Converting numeric columns...\n",
      "       All numeric columns converted\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 4: Convert Data Types\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"4. CONVERTING DATA TYPES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 4.1 Convert Budget and Revenue to Millions USD\n",
    "print(\"\\n  4.1 Converting budget and revenue to millions USD...\")\n",
    "\n",
    "# Convert to numeric first (in case they're strings)\n",
    "df_clean['budget'] = pd.to_numeric(df_clean['budget'], errors='coerce')\n",
    "df_clean['revenue'] = pd.to_numeric(df_clean['revenue'], errors='coerce')\n",
    "\n",
    "# Replace zeros with NaN (unrealistic values)\n",
    "df_clean.loc[df_clean['budget'] == 0, 'budget'] = np.nan\n",
    "df_clean.loc[df_clean['revenue'] == 0, 'revenue'] = np.nan\n",
    "\n",
    "# Convert to millions\n",
    "df_clean['budget_musd'] = df_clean['budget'] / 1_000_000\n",
    "df_clean['revenue_musd'] = df_clean['revenue'] / 1_000_000\n",
    "\n",
    "# Drop original columns\n",
    "df_clean = df_clean.drop(columns=['budget', 'revenue'])\n",
    "\n",
    "print(f\"       Budget and revenue converted to millions USD\")\n",
    "print(f\"       Zeros replaced with NaN\")\n",
    "\n",
    "# 4.2 Convert Release Date to Datetime\n",
    "print(\"\\n  4.2 Converting release_date to datetime...\")\n",
    "df_clean['release_date'] = pd.to_datetime(df_clean['release_date'], errors='coerce')\n",
    "print(f\"       Release date converted to datetime format\")\n",
    "\n",
    "# 4.3 Convert ID and Popularity to Numeric\n",
    "print(\"\\n  4.3 Converting numeric columns...\")\n",
    "df_clean['id'] = pd.to_numeric(df_clean['id'], errors='coerce')\n",
    "df_clean['popularity'] = pd.to_numeric(df_clean['popularity'], errors='coerce')\n",
    "df_clean['runtime'] = pd.to_numeric(df_clean['runtime'], errors='coerce')\n",
    "df_clean['vote_average'] = pd.to_numeric(df_clean['vote_average'], errors='coerce')\n",
    "df_clean['vote_count'] = pd.to_numeric(df_clean['vote_count'], errors='coerce')\n",
    "print(f\"       All numeric columns converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e01dcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "5. HANDLING MISSING VALUES\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  5.1 Handling runtime zeros...\n",
      "       Replaced 0 runtime zeros with NaN\n",
      "\n",
      "  5.2 Handling vote_count zeros...\n",
      "\n",
      "  5.3 Replacing placeholder text...\n",
      "       Replaced placeholders in text columns\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 5: Handle Missing Values & Special Cases\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"5. HANDLING MISSING VALUES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 5.1 Replace runtime = 0 with NaN\n",
    "print(\"\\n  5.1 Handling runtime zeros...\")\n",
    "runtime_zeros = (df_clean['runtime'] == 0).sum()\n",
    "df_clean.loc[df_clean['runtime'] == 0, 'runtime'] = np.nan\n",
    "print(f\"       Replaced {runtime_zeros} runtime zeros with NaN\")\n",
    "\n",
    "# 5.2 Handle vote_count = 0\n",
    "print(\"\\n  5.2 Handling vote_count zeros...\")\n",
    "vote_zeros = (df_clean['vote_count'] == 0).sum()\n",
    "if vote_zeros > 0:\n",
    "    # If vote_count = 0, also set vote_average to NaN\n",
    "    df_clean.loc[df_clean['vote_count'] == 0, 'vote_average'] = np.nan\n",
    "    print(f\"       Set vote_average to NaN for {vote_zeros} movies with no votes\")\n",
    "\n",
    "# 5.3 Replace placeholder text with NaN\n",
    "print(\"\\n  5.3 Replacing placeholder text...\")\n",
    "placeholder_values = ['No Data', 'no data', 'N/A', 'n/a', '']\n",
    "\n",
    "for col in ['overview', 'tagline']:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].replace(placeholder_values, np.nan)\n",
    "\n",
    "print(f\"       Replaced placeholders in text columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c63d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "6. FILTERING INVALID ROWS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  6.1 Removing rows with missing ID or title...\n",
      "       Removed 0 rows\n",
      "\n",
      "  6.2 Removing duplicate movie IDs...\n",
      "       Removed 0 duplicates\n",
      "\n",
      "  6.3 Filtering rows with sufficient data (≥10 non-NaN columns)...\n",
      "       Removed 0 rows with insufficient data\n",
      "\n",
      "  6.4 Filtering to keep only 'Released' movies...\n",
      "       Kept only Released movies: removed 0 rows\n",
      "       Dropped 'status' column\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 6: Filter & Remove Invalid Rows\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"6. FILTERING INVALID ROWS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "initial_rows = len(df_clean)\n",
    "\n",
    "# 6.1 Remove rows with unknown ID or title\n",
    "print(\"\\n  6.1 Removing rows with missing ID or title...\")\n",
    "df_clean = df_clean.dropna(subset=['id', 'title'])\n",
    "print(f\"       Removed {initial_rows - len(df_clean)} rows\")\n",
    "\n",
    "# 6.2 Remove duplicates based on ID\n",
    "print(\"\\n  6.2 Removing duplicate movie IDs...\")\n",
    "before_dup = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates(subset=['id'], keep='first')\n",
    "print(f\"       Removed {before_dup - len(df_clean)} duplicates\")\n",
    "\n",
    "# 6.3 Keep only rows with at least 10 non-NaN columns\n",
    "print(\"\\n  6.3 Filtering rows with sufficient data (≥10 non-NaN columns)...\")\n",
    "before_filter = len(df_clean)\n",
    "df_clean = df_clean[df_clean.notna().sum(axis=1) >= 10]\n",
    "print(f\"       Removed {before_filter - len(df_clean)} rows with insufficient data\")\n",
    "\n",
    "# 6.4 Filter to include only 'Released' movies\n",
    "print(\"\\n  6.4 Filtering to keep only 'Released' movies...\")\n",
    "if 'status' in df_clean.columns:\n",
    "    before_status = len(df_clean)\n",
    "    df_clean = df_clean[df_clean['status'] == 'Released']\n",
    "    print(f\"       Kept only Released movies: removed {before_status - len(df_clean)} rows\")\n",
    "    \n",
    "    # Drop status column (no longer needed)\n",
    "    df_clean = df_clean.drop(columns=['status'])\n",
    "    print(f\"       Dropped 'status' column\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6743b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "7. REORDERING COLUMNS TO FINAL STRUCTURE\n",
      "----------------------------------------------------------------------\n",
      " Columns reordered to final structure\n",
      " Final column count: 22\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 7: Reorder Columns (Final Structure)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"7. REORDERING COLUMNS TO FINAL STRUCTURE\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Define desired column order\n",
    "desired_columns = [\n",
    "    'id', 'title', 'tagline', 'release_date', 'genres', \n",
    "    'belongs_to_collection', 'original_language', 'budget_musd', \n",
    "    'revenue_musd', 'production_companies', 'production_countries', \n",
    "    'vote_count', 'vote_average', 'popularity', 'runtime', \n",
    "    'overview', 'spoken_languages', 'poster_path', 'cast', \n",
    "    'cast_size', 'director', 'crew_size'\n",
    "]\n",
    "\n",
    "# Only keep columns that exist\n",
    "final_columns = [col for col in desired_columns if col in df_clean.columns]\n",
    "\n",
    "# Reorder\n",
    "df_clean = df_clean[final_columns]\n",
    "\n",
    "print(f\" Columns reordered to final structure\")\n",
    "print(f\" Final column count: {len(final_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a774d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "8. RESETTING INDEX\n",
      "----------------------------------------------------------------------\n",
      " Index reset\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 8: Reset Index\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"8. RESETTING INDEX\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "print(\" Index reset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c1849ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CLEANING COMPLETE! \n",
      "======================================================================\n",
      "\n",
      "Final Dataset Summary:\n",
      "  • Total movies: 18\n",
      "  • Total columns: 22\n",
      "  • Missing values: 2\n",
      "  • Date range: 1997 - 2019\n",
      "  • Budget range: $125.0M - $356.0M\n",
      "  • Revenue range: $1243.2M - $2923.7M\n",
      "\n",
      "\n",
      " Sample of cleaned data (first 3 rows, key columns):\n",
      "----------------------------------------------------------------------\n",
      "                          title release_date  \\\n",
      "0             Avengers: Endgame   2019-04-24   \n",
      "1                        Avatar   2009-12-15   \n",
      "2  Star Wars: The Force Awakens   2015-12-15   \n",
      "\n",
      "                                     genres  budget_musd  revenue_musd  \\\n",
      "0          Adventure|Science Fiction|Action        356.0   2799.439100   \n",
      "1  Action|Adventure|Fantasy|Science Fiction        237.0   2923.706026   \n",
      "2          Adventure|Action|Science Fiction        245.0   2068.223624   \n",
      "\n",
      "   vote_average  \n",
      "0         8.237  \n",
      "1         7.594  \n",
      "2         7.255  \n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SAVING CLEANED DATA\n",
      "----------------------------------------------------------------------\n",
      " Saved to: movies_clean.csv\n",
      "\n",
      "======================================================================\n",
      " DATA CLEANING PHASE COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "You're now ready for Phase 3: KPI Analysis & Rankings! \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY & SAVE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLEANING COMPLETE! \")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Final Dataset Summary:\n",
    "  • Total movies: {len(df_clean)}\n",
    "  • Total columns: {len(df_clean.columns)}\n",
    "  • Missing values: {df_clean.isnull().sum().sum()}\n",
    "  • Date range: {df_clean['release_date'].min().year} - {df_clean['release_date'].max().year}\n",
    "  • Budget range: ${df_clean['budget_musd'].min():.1f}M - ${df_clean['budget_musd'].max():.1f}M\n",
    "  • Revenue range: ${df_clean['revenue_musd'].min():.1f}M - ${df_clean['revenue_musd'].max():.1f}M\n",
    "\"\"\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\n Sample of cleaned data (first 3 rows, key columns):\")\n",
    "print(\"-\"*70)\n",
    "display_cols = ['title', 'release_date', 'genres', 'budget_musd', 'revenue_musd', 'vote_average']\n",
    "display_cols = [col for col in display_cols if col in df_clean.columns]\n",
    "print(df_clean[display_cols].head(3))\n",
    "\n",
    "# Save to CSV\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"SAVING CLEANED DATA\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_clean.to_csv('movies_clean.csv', index=False)\n",
    "print(\" Saved to: movies_clean.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" DATA CLEANING PHASE COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYou're now ready for Phase 3: KPI Analysis & Rankings! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af3a348c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "3. PROCESSING CAST & CREW DATA\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  3.3 Extracting cast names...\n",
      "       Top 5 cast members extracted per movie\n",
      "\n",
      "  3.4 Calculating cast size...\n",
      "       Cast size calculated\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 3: Process Cast & Crew\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"3. PROCESSING CAST & CREW DATA\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 3.1 Extract Director\n",
    "if 'crew' in df_clean.columns:\n",
    "    print(\"\\n  3.1 Finding directors...\")\n",
    "    df_clean['director'] = df_clean['crew'].apply(find_director)\n",
    "    directors_found = df_clean['director'].notna().sum()\n",
    "    print(f\"       Directors found for {directors_found} movies\")\n",
    "\n",
    "# 3.2 Calculate Crew Size\n",
    "if 'crew' in df_clean.columns:\n",
    "    print(\"\\n  3.2 Calculating crew size...\")\n",
    "    df_clean['crew_size'] = df_clean['crew'].apply(\n",
    "        lambda x: len(safe_eval(x)) if safe_eval(x) else 0\n",
    "    )\n",
    "    print(f\"       Crew size calculated\")\n",
    "\n",
    "# 3.3 Extract Cast Names\n",
    "if 'cast' in df_clean.columns:\n",
    "    print(\"\\n  3.3 Extracting cast names...\")\n",
    "    df_clean['cast'] = df_clean['cast'].apply(lambda x: extract_cast_names(x, max_names=5))\n",
    "    print(f\"       Top 5 cast members extracted per movie\")\n",
    "\n",
    "# 3.4 Calculate Cast Size (before extraction)\n",
    "# We need to recalculate from raw data since we already modified cast\n",
    "if 'cast' in df.columns:\n",
    "    print(\"\\n  3.4 Calculating cast size...\")\n",
    "    df_clean['cast_size'] = df['cast'].apply(\n",
    "        lambda x: len(safe_eval(x)) if safe_eval(x) else 0\n",
    "    )\n",
    "    print(f\"       Cast size calculated\")\n",
    "\n",
    "# Drop the crew column (we don't need it anymore)\n",
    "if 'crew' in df_clean.columns:\n",
    "    df_clean = df_clean.drop(columns=['crew'])\n",
    "    print(\"\\n   Dropped 'crew' column (no longer needed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "668a6ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "4. CONVERTING DATA TYPES\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  4.1 Converting budget and revenue to millions USD...\n",
      "       Columns 'budget' and/or 'revenue' not found — skipping conversion.\n",
      "       Budget and revenue converted to millions USD\n",
      "       Zeros replaced with NaN\n",
      "\n",
      "  4.2 Converting release_date to datetime...\n",
      "       Release date converted to datetime format\n",
      "\n",
      "  4.3 Converting numeric columns...\n",
      "       All numeric columns converted\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 4: Convert Data Types\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"4. CONVERTING DATA TYPES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 4.1 Convert Budget and Revenue to Millions USD\n",
    "print(\"\\n  4.1 Converting budget and revenue to millions USD...\")\n",
    "\n",
    "if 'budget' in df_clean.columns and 'revenue' in df_clean.columns:\n",
    "\n",
    "    # Convert to numeric\n",
    "    df_clean['budget'] = pd.to_numeric(df_clean['budget'], errors='coerce')\n",
    "    df_clean['revenue'] = pd.to_numeric(df_clean['revenue'], errors='coerce')\n",
    "\n",
    "    # Replace zeros with NaN\n",
    "    df_clean.loc[df_clean['budget'] == 0, 'budget'] = np.nan\n",
    "    df_clean.loc[df_clean['revenue'] == 0, 'revenue'] = np.nan\n",
    "\n",
    "    # Convert to millions\n",
    "    df_clean['budget_musd'] = df_clean['budget'] / 1_000_000\n",
    "    df_clean['revenue_musd'] = df_clean['revenue'] / 1_000_000\n",
    "\n",
    "    # Drop originals\n",
    "    df_clean = df_clean.drop(columns=['budget', 'revenue'])\n",
    "\n",
    "    print(\"       Budget and revenue converted to millions USD\")\n",
    "    print(\"       Zeros replaced with NaN\")\n",
    "\n",
    "else:\n",
    "    print(\"       Columns 'budget' and/or 'revenue' not found — skipping conversion.\")\n",
    "\n",
    "print(f\"       Budget and revenue converted to millions USD\")\n",
    "print(f\"       Zeros replaced with NaN\")\n",
    "\n",
    "# 4.2 Convert Release Date to Datetime\n",
    "print(\"\\n  4.2 Converting release_date to datetime...\")\n",
    "df_clean['release_date'] = pd.to_datetime(df_clean['release_date'], errors='coerce')\n",
    "print(f\"       Release date converted to datetime format\")\n",
    "\n",
    "# 4.3 Convert ID and Popularity to Numeric\n",
    "print(\"\\n  4.3 Converting numeric columns...\")\n",
    "df_clean['id'] = pd.to_numeric(df_clean['id'], errors='coerce')\n",
    "df_clean['popularity'] = pd.to_numeric(df_clean['popularity'], errors='coerce')\n",
    "df_clean['runtime'] = pd.to_numeric(df_clean['runtime'], errors='coerce')\n",
    "df_clean['vote_average'] = pd.to_numeric(df_clean['vote_average'], errors='coerce')\n",
    "df_clean['vote_count'] = pd.to_numeric(df_clean['vote_count'], errors='coerce')\n",
    "print(f\"       All numeric columns converted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "795f1986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "5. HANDLING MISSING VALUES\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  5.1 Handling runtime zeros...\n",
      "       Replaced 0 runtime zeros with NaN\n",
      "\n",
      "  5.2 Handling vote_count zeros...\n",
      "\n",
      "  5.3 Replacing placeholder text...\n",
      "       Replaced placeholders in text columns\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 5: Handle Missing Values & Special Cases\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"5. HANDLING MISSING VALUES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# 5.1 Replace runtime = 0 with NaN\n",
    "print(\"\\n  5.1 Handling runtime zeros...\")\n",
    "runtime_zeros = (df_clean['runtime'] == 0).sum()\n",
    "df_clean.loc[df_clean['runtime'] == 0, 'runtime'] = np.nan\n",
    "print(f\"       Replaced {runtime_zeros} runtime zeros with NaN\")\n",
    "\n",
    "# 5.2 Handle vote_count = 0\n",
    "print(\"\\n  5.2 Handling vote_count zeros...\")\n",
    "vote_zeros = (df_clean['vote_count'] == 0).sum()\n",
    "if vote_zeros > 0:\n",
    "    # If vote_count = 0, also set vote_average to NaN\n",
    "    df_clean.loc[df_clean['vote_count'] == 0, 'vote_average'] = np.nan\n",
    "    print(f\"       Set vote_average to NaN for {vote_zeros} movies with no votes\")\n",
    "\n",
    "# 5.3 Replace placeholder text with NaN\n",
    "print(\"\\n  5.3 Replacing placeholder text...\")\n",
    "placeholder_values = ['No Data', 'no data', 'N/A', 'n/a', '']\n",
    "\n",
    "for col in ['overview', 'tagline']:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].replace(placeholder_values, np.nan)\n",
    "\n",
    "print(f\"       Replaced placeholders in text columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bf70221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "6. FILTERING INVALID ROWS\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "  6.1 Removing rows with missing ID or title...\n",
      "       Removed 0 rows\n",
      "\n",
      "  6.2 Removing duplicate movie IDs...\n",
      "       Removed 0 duplicates\n",
      "\n",
      "  6.3 Filtering rows with sufficient data (≥10 non-NaN columns)...\n",
      "       Removed 0 rows with insufficient data\n",
      "\n",
      "  6.4 Filtering to keep only 'Released' movies...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 6: Filter & Remove Invalid Rows\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"6. FILTERING INVALID ROWS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "initial_rows = len(df_clean)\n",
    "\n",
    "# 6.1 Remove rows with unknown ID or title\n",
    "print(\"\\n  6.1 Removing rows with missing ID or title...\")\n",
    "df_clean = df_clean.dropna(subset=['id', 'title'])\n",
    "print(f\"       Removed {initial_rows - len(df_clean)} rows\")\n",
    "\n",
    "# 6.2 Remove duplicates based on ID\n",
    "print(\"\\n  6.2 Removing duplicate movie IDs...\")\n",
    "before_dup = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates(subset=['id'], keep='first')\n",
    "print(f\"       Removed {before_dup - len(df_clean)} duplicates\")\n",
    "\n",
    "# 6.3 Keep only rows with at least 10 non-NaN columns\n",
    "print(\"\\n  6.3 Filtering rows with sufficient data (≥10 non-NaN columns)...\")\n",
    "before_filter = len(df_clean)\n",
    "df_clean = df_clean[df_clean.notna().sum(axis=1) >= 10]\n",
    "print(f\"       Removed {before_filter - len(df_clean)} rows with insufficient data\")\n",
    "\n",
    "# 6.4 Filter to include only 'Released' movies\n",
    "print(\"\\n  6.4 Filtering to keep only 'Released' movies...\")\n",
    "if 'status' in df_clean.columns:\n",
    "    before_status = len(df_clean)\n",
    "    df_clean = df_clean[df_clean['status'] == 'Released']\n",
    "    print(f\"       Kept only Released movies: removed {before_status - len(df_clean)} rows\")\n",
    "    \n",
    "    # Drop status column (no longer needed)\n",
    "    df_clean = df_clean.drop(columns=['status'])\n",
    "    print(f\"       Dropped 'status' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89b39567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "7. REORDERING COLUMNS TO FINAL STRUCTURE\n",
      "----------------------------------------------------------------------\n",
      " Columns reordered to final structure\n",
      " Final column count: 22\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 7: Reorder Columns (Final Structure)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"7. REORDERING COLUMNS TO FINAL STRUCTURE\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Define desired column order\n",
    "desired_columns = [\n",
    "    'id', 'title', 'tagline', 'release_date', 'genres', \n",
    "    'belongs_to_collection', 'original_language', 'budget_musd', \n",
    "    'revenue_musd', 'production_companies', 'production_countries', \n",
    "    'vote_count', 'vote_average', 'popularity', 'runtime', \n",
    "    'overview', 'spoken_languages', 'poster_path', 'cast', \n",
    "    'cast_size', 'director', 'crew_size'\n",
    "]\n",
    "\n",
    "# Only keep columns that exist\n",
    "final_columns = [col for col in desired_columns if col in df_clean.columns]\n",
    "\n",
    "# Reorder\n",
    "df_clean = df_clean[final_columns]\n",
    "\n",
    "print(f\" Columns reordered to final structure\")\n",
    "print(f\" Final column count: {len(final_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca31cce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "8. RESETTING INDEX\n",
      "----------------------------------------------------------------------\n",
      " Index reset\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEANING STEP 8: Reset Index\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"8. RESETTING INDEX\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "print(\" Index reset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a281f68",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
